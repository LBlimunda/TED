\documentclass[12pt]{article}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{geometry}
\geometry{a4paper, margin=2.5cm}

\title{Theorem of Democratic Entropy (TED): \\
How Large-Scale Aggregation Flattens Collective Outcomes}
\author{Lara Raquel Rodrigues Branco Arsénio}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
When many people make a decision together, diversity disappears. 
The Theorem of Democratic Entropy (TED) formalizes this. We define 
a collective quality-of-life index $Q$ as the median of individual 
preferences $p_i \in [0,100]$. As the group grows, $Q_n$ converges 
to the median, variance $\sigma(Q_n)$ vanishes, and outcomes 
flatten to a “minimum common denominator.” 

We introduce $n_{\text{crit}}$, the threshold beyond which the collapse 
is inevitable. Simulations under uniform, bimodal, and skewed 
distributions illustrate the effect. Applications range from 
political elections to AI/ML systems. The median is defended as a 
concept-proof abstraction: simple, neutral, and robust.
\end{abstract}

\section{Introduction}
Big groups make decisions differently than small ones. In small 
groups, voices matter. In large ones, they don't. The result is 
median outcomes, mediocrity by scale. TED formalizes this 
inevitable flattening. 

This is not an attack on democracy. It's a description of a structural 
limit: aggregation at scale erases nuance.

\section{Definitions}
Each individual $i$ has a preference $p_i \in [0,100]$. 
$0$ is worst, $100$ is best. The collective quality-of-life is:
\[
Q_n = 100 \times \mathrm{med}(p_1, p_2, \dots, p_n).
\]

The spread of possible outcomes:
\[
\sigma(Q_n) = \frac{50}{f(\mu)\sqrt{n}},
\]
where $f(\mu)$ is the probability density at the median $\mu$.

\section{Theorem of Democratic Entropy}
\begin{theorem}[TED]
As $n \to \infty$, $\sigma(Q_n) \to 0$ and $Q_n \to \mu$. 
The system collapses to the median, independent of the original 
distribution.
\end{theorem}

We call this collapse \emph{democratic entropy}.

\section{Critical Threshold}
The critical number of participants is:
\[
n_{\text{crit}} \geq \left(\frac{50}{f(\mu)}\right)^2.
\]

Beyond this, individual voices barely matter.

\section{Analytical Calculations}
\subsection{Uniform Distribution}
For $f(p)=1/100$:
\[
\sigma(Q_n) = \frac{50}{\sqrt{n}}.
\]

\subsection{Bimodal Distribution}
Two peaks at $a$ and $b$ lead to a median at $(a+b)/2$. 
Variance decreases as $n$ grows.

\subsection{Skewed Distribution}
The median shifts toward the majority mass. Minority 
preferences vanish once $n > n_{\text{crit}}$.

\section{Simulations}
We include example figures to illustrate TED:

\begin{figure}[h]
    \centering
    % Placeholder for variance plot
    \fbox{\parbox[c][5cm][c]{0.7\textwidth}{\centering Variance $\sigma(Q_n)$ vs $n$}}
    \caption{Variance $\sigma(Q_n)$ as a function of $n$ for different distributions.}
\end{figure}

\begin{figure}[h]
    \centering
    % Placeholder for Q_n convergence
    \fbox{\parbox[c][5cm][c]{0.7\textwidth}{\centering Convergence of $Q_n$ for Uniform, Bimodal, Skewed}}
    \caption{Convergence of $Q_n$ under uniform, bimodal, and skewed distributions.}
\end{figure}

\section{Scenario Comparison}
\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|}
\hline
Distribution & Outcome of $Q_n$ & Meaning \\
\hline
Uniform & Smoothly to 50 & Flattening by scale \\
Bimodal & Median between peaks & Artificial compromise \\
Skewed & Dominated by majority & Minority suppressed \\
\hline
\end{tabular}
\caption{TED scenarios.}
\end{table}

\section{Median as Concept-Proof}
The median is simple, robust, neutral. It captures the structural 
effect without extra assumptions. Complex systems may use weights 
or negotiation, but the median shows the core phenomenon clearly.

\section{Applications}
\subsection{Democracy}
Large electorates converge to median positions. Individual nuance 
is lost. Supranational bodies amplify this effect.

\subsection{AI and Machine Learning}
Ensembles, voting classifiers, LLMs: aggregation leads to “median 
intelligence”—safe but mediocre. TED explains why.

\subsection{Social Networks}
Likes, shares, algorithms: content converges to the bland middle, 
originality is suppressed.

\section{Discussion}
TED reveals a paradox: more participants often reduce the 
quality of collective decisions. Implications:  
- Smaller federated units preserve diversity,  
- AI/ML can be designed to retain variance,  
- Social platforms could rethink aggregation metrics.

\section{Conclusion}
TED shows that scale itself flattens outcomes. The median and 
$n_{\text{crit}}$ make this clear. Understanding TED helps design 
systems that maintain diversity even as size grows.

\bibliographystyle{plain}
\begin{thebibliography}{9}

\bibitem{arrow}
Arrow, K. J. (1950).
A difficulty in the concept of social welfare.
\textit{Journal of Political Economy}, 58(4), 328–346.

\bibitem{condorcet}
Condorcet, M. (1785).
\textit{Essai sur l'application de l'analyse à la probabilité des décisions rendues à la pluralité des voix}. Paris.

\bibitem{ml}
Dietterich, T. G. (2000).
Ensemble methods in machine learning.
\textit{International workshop on multiple classifier systems}. Springer.

\bibitem{llm}
Bommasani, R. et al. (2021).
On the Opportunities and Risks of Foundation Models.
\textit{arXiv preprint arXiv:2108.07258}.

\end{thebibliography}

\end{document}
